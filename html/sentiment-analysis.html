

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Sentiment Analysis &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_override.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Image Classification" href="image-classification.html" />
    <link rel="prev" title="LSTMLM" href="language-model/lstmlm.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-existing-models.html">Using Existing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="distr-training.html">Multi-GPU and Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed-precision.html">Mixed Precision Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimizers.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="speech-recognition.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="speech-commands.html">Speech Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="speech-synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="machine-translation.html">Machine Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="language-model.html">Language Model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Sentiment Analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#models">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="language-model/lstmlm.html">LSTMLM</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#get-data">Get data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inference">Inference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="image-classification.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="interactive-infer-demos.html">Interactive Infer Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="adding-new-models.html">Adding new models</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-docs/modules.html">API documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Sentiment Analysis</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/sentiment-analysis.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="sentiment-analysis">
<span id="id1"></span><h1>Sentiment Analysis<a class="headerlink" href="#sentiment-analysis" title="Permalink to this headline">¶</a></h1>
<div class="section" id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<p>The model we use for sentiment analysis is the same one we use for the LSTM language model, except that the last output dimension is the number of sentiment classes instead of the vocabulary size. This sameness allows the sentiment analysis model to use the model pretrained on the language model for this task. You can choose to train the sentiment analysis task from scratch, or from the pretrained language model.</p>
<p>In this model, each source sentence is run through the LSTM cells. The last hidden state at the end of the sequence is then passed into the output projection layer before softmax is performed to get the predicted sentiment. If the parameter <code class="docutils literal notranslate"><span class="pre">use_cell_state</span></code> is set to True, the last cell state at the end of the sequence is concatenated to the last hidden state.</p>
<p>The datasets we currently support include SST (Stanford Sentiment Treebank) and IMDB reviews.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="25%" />
<col width="50%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Model description</th>
<th class="head">Config file</th>
<th class="head">Checkpoint</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><span class="xref std std-doc">IDMB</span></td>
<td><a class="reference external" href="https://github.com/NVIDIA/OpenSeq2Seq/blob/master/example_configs/transfer/imdb-wkt103.py">imdb-wkt103.py</a></td>
<td>Accuracy=?</td>
</tr>
<tr class="row-odd"><td><span class="xref std std-doc">SST</span></td>
<td><a class="reference external" href="https://github.com/NVIDIA/OpenSeq2Seq/blob/master/example_configs/transfer/sst-wkt2.py">sst-wkt2.py</a></td>
<td>Accuracy=?</td>
</tr>
</tbody>
</table>
<p>The model specification and training parameters can be found in the corresponding config file.</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<div class="section" id="get-data">
<h3>Get data<a class="headerlink" href="#get-data" title="Permalink to this headline">¶</a></h3>
<p>The SST (Stanford Sentiment Treebank) dataset contains of 10,662 sentences, half of them positive, half of them negative. These sentences are fairly short with the median length of 19 tokens. You can download the pre-processed version of the dataset <cite>here &lt;https://github.com/NVIDIA/sentiment-discovery/tree/master/data/binary_sst&gt;</cite>. The pre-processed dataset contains the files <cite>train.csv</cite>, <cite>valid.csv</cite>, <cite>test.csv</cite>. The dalay layer used to process this dataset is called SSTDataLayer.</p>
<p>The IMDB Dataset contains 50,000 labeled samples of much longer length. The median length is 205 tokens. Half of them are deemed positive and the other half negative. The train set, which contains of 25,000 samples, is separated into a train set of 24,000 samples and a validation set of 1,000 samples. The dalay layer used to process this dataset is called SSTDataLayer. The dataset can be downloaded <cite>here &lt;http://ai.stanford.edu/~amaas/data/sentiment/&gt;</cite>.</p>
<p>If you want to use a trained language model for this task, make sure that your dataset is processed in the same way the dataset used for the language model was.</p>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>Next let’s create a simple LSTM language model by defining a config file for it or using one of the config files defined in <code class="docutils literal notranslate"><span class="pre">example_configs/transfer</span></code>.</p>
<ul class="simple">
<li>if you want to use a pretrained language model, specify the location of the pretrained language model using the parameter <code class="docutils literal notranslate"><span class="pre">load_model</span></code>.</li>
<li>change <code class="docutils literal notranslate"><span class="pre">data_root</span></code> to point to the directory containing the raw dataset used to train your language model, for example, the IMDB dataset downloaded above.</li>
<li>change <code class="docutils literal notranslate"><span class="pre">processed_data_folder</span></code> to point to the location where you want to store the processed dataset. If the dataset has been pre-procesed before, the data layer can just load the data from this location.</li>
<li>update other hyper parameters such as number of layers, number of hidden units, cell type, loss function, learning rate, optimizer, etc. to meet your needs.</li>
<li>choose <code class="docutils literal notranslate"><span class="pre">dtype</span></code> to be <code class="docutils literal notranslate"><span class="pre">&quot;mixed&quot;</span></code> if you want to use mixed-precision training, or <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> to train only in FP32.</li>
</ul>
<p>For example, your config file is <code class="docutils literal notranslate"><span class="pre">lstm-wkt103-mixed.py</span></code>. To train without Horovod, update <code class="docutils literal notranslate"><span class="pre">use_horovod</span></code> to False in the config file and run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">run</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config_file</span><span class="o">=</span><span class="n">example_configs</span><span class="o">/</span><span class="n">transfer</span><span class="o">/</span><span class="n">imdb</span><span class="o">-</span><span class="n">wkt2</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">mode</span><span class="o">=</span><span class="n">train_eval</span> <span class="o">--</span><span class="n">enable_logs</span>
</pre></div>
</div>
<p>When training with Horovod, use the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpiexec</span> <span class="o">--</span><span class="n">allow</span><span class="o">-</span><span class="n">run</span><span class="o">-</span><span class="k">as</span><span class="o">-</span><span class="n">root</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">num_gpus</span><span class="o">&gt;</span> <span class="n">python</span> <span class="n">run</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config_file</span><span class="o">=</span><span class="n">example_configs</span><span class="o">/</span><span class="n">transfer</span><span class="o">/</span><span class="n">imdb</span><span class="o">-</span><span class="n">wkt2</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">mode</span><span class="o">=</span><span class="n">train_eval</span> <span class="o">--</span><span class="n">enable_logs</span>
</pre></div>
</div>
<p>Some things to keep in mind:</p>
<ul class="simple">
<li>Don’t forget to update <code class="docutils literal notranslate"><span class="pre">num_gpus</span></code> to the number of GPUs you want to use.</li>
<li>If your GPUs run out of memory, reduce the <code class="docutils literal notranslate"><span class="pre">batch_size_per_gpu</span></code></li>
</ul>
<p>parameter.</p>
</div>
<div class="section" id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h3>
<p>Running in the mode <code class="docutils literal notranslate"><span class="pre">eval</span></code> will evaluate your model on the evaluation set:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">run</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config_file</span><span class="o">=</span><span class="n">example_configs</span><span class="o">/</span><span class="n">transfer</span><span class="o">/</span><span class="n">imdb</span><span class="o">-</span><span class="n">wkt2</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">mode</span><span class="o">=</span><span class="nb">eval</span> <span class="o">--</span><span class="n">enable_logs</span>
</pre></div>
</div>
<p>Running in the mode <code class="docutils literal notranslate"><span class="pre">infer</span></code> will evaluate your model on the test set:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">run</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config_file</span><span class="o">=</span><span class="n">example_configs</span><span class="o">/</span><span class="n">transfer</span><span class="o">/</span><span class="n">imdb</span><span class="o">-</span><span class="n">wkt2</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">mode</span><span class="o">=</span><span class="n">test</span> <span class="o">--</span><span class="n">enable_logs</span>
</pre></div>
</div>
<p>The performance of the model is reported on accuracy and F1 scores.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="image-classification.html" class="btn btn-neutral float-right" title="Image Classification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="language-model/lstmlm.html" class="btn btn-neutral" title="LSTMLM" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>